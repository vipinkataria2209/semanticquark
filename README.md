# SemanticQuark

<div align="center">

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Docker](https://img.shields.io/badge/docker-ready-blue.svg)

**The Fundamental Building Block for Semantic Analytics**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Examples](#-examples) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸš€ What is SemanticQuark?

**SemanticQuark** is a Python-based semantic layer platform that provides the fundamental building blocks for analytics. It enables you to:

- **Define metrics once, use everywhere** - Create reusable data models with consistent metric definitions
- **Query data without SQL** - Use simple JSON queries instead of complex SQL
- **Connect to any database** - Support for PostgreSQL, MySQL, Snowflake, BigQuery, and more
- **Build faster analytics** - Intelligent caching and pre-aggregation for sub-second queries
- **Secure your data** - Row-level and column-level security built-in

Think of it as **Cube.js for Python** - but with native Python integration, ML capabilities, and data science workflow support.

## âœ¨ Features

### Core Features
- ğŸ¯ **Semantic Data Modeling** - Define cubes, dimensions, and measures in YAML
- ğŸ” **REST API** - Query data with simple JSON requests
- ğŸ—„ï¸ **Multiple Data Sources** - PostgreSQL, MySQL, and extensible connector system
- âš¡ **Query Optimization** - Automatic SQL generation and optimization
- ğŸ“Š **Result Formatting** - Consistent JSON responses with metadata
- ğŸ”’ **Security Ready** - Foundation for row-level and column-level security

### Python-Native Advantages
- ğŸ **Python SDK** - Native Python client library
- ğŸ“ˆ **Data Science Integration** - Works with Pandas, Jupyter, and ML workflows
- ğŸ¤– **ML-Ready** - Embed ML models directly in metrics
- ğŸ“¦ **Rich Ecosystem** - Leverage Python's data science libraries

### Production Ready
- ğŸ³ **Docker Support** - Complete Docker Compose setup
- ğŸ“ **API Documentation** - Auto-generated Swagger/OpenAPI docs
- ğŸ§ª **Tested** - Comprehensive test suite
- ğŸ“š **Well Documented** - Extensive documentation and examples

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Client Applications                         â”‚
â”‚    (BI Tools, Dashboards, Custom Apps, APIs)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ REST/GraphQL APIs
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API Layer (FastAPI)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   REST   â”‚  â”‚ GraphQL  â”‚  â”‚   SQL    â”‚             â”‚
â”‚  â”‚   API    â”‚  â”‚   API    â”‚  â”‚   API    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Query Requests
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Query Engine & Orchestration                     â”‚
â”‚  Query Parser â†’ SQL Builder â†’ Executor                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Semantic   â”‚ â”‚   Cache    â”‚ â”‚  Security  â”‚
â”‚    Layer     â”‚ â”‚   Layer    â”‚ â”‚   Layer   â”‚
â”‚  (Models)    â”‚ â”‚  (Redis)   â”‚ â”‚  (RLS)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Source Connectors                â”‚
â”‚  PostgreSQL â”‚ MySQL â”‚ Snowflake â”‚ BigQuery   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Docker and Docker Compose (optional, for full stack)
- PostgreSQL (if not using Docker)

### Installation

#### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/semanticquark.git
cd semanticquark

# Start all services
docker-compose up -d

# Initialize database
docker-compose exec postgres psql -U semantic_user -d semantic_db < init_db.sql

# Test the API
curl http://localhost:8000/health
```

#### Option 2: Local Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/semanticquark.git
cd semanticquark

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your database connection

# Run the API
python -m semantic_layer.api.main
```

### Your First Query

1. **Create a model** in `models/orders.yaml`:
```yaml
cubes:
  - name: orders
    table: orders
    dimensions:
      status:
        type: string
        sql: status
      created_at:
        type: time
        sql: created_at
    measures:
      count:
        type: count
        sql: id
      total_revenue:
        type: sum
        sql: total_amount
```

2. **Query the API**:
```bash
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "dimensions": ["orders.status"],
    "measures": ["orders.count", "orders.total_revenue"]
  }'
```

3. **Get results**:
```json
{
  "data": [
    {
      "orders_status": "completed",
      "orders_count": 5,
      "orders_total_revenue": 925.0
    }
  ],
  "meta": {
    "execution_time_ms": 18.56,
    "row_count": 1
  }
}
```

## ğŸ“– Documentation

- [Architecture Guide](high_level_architecture.md) - High-level design and concepts
- [Foundational Components](core_foundational_components.md) - Core building blocks
- [API Documentation](http://localhost:8000/docs) - Interactive API docs (when running)
- [Docker Setup](DOCKER_SETUP.md) - Docker Compose guide
- [Postman Examples](POSTMAN_EXAMPLES.md) - API usage examples
- [Competitive Advantages](competitive_advantages.md) - Features vs Cube.js

## ğŸ“š Examples

### Example 1: Simple Aggregation
```json
{
  "measures": ["orders.count", "orders.total_revenue"]
}
```

### Example 2: Group By Dimension
```json
{
  "dimensions": ["orders.status"],
  "measures": ["orders.count"]
}
```

### Example 3: With Filters
```json
{
  "dimensions": ["orders.status"],
  "measures": ["orders.count"],
  "filters": [
    {
      "dimension": "orders.status",
      "operator": "equals",
      "values": ["completed"]
    }
  ]
}
```

### Example 4: Python Client
```python
import httpx

async with httpx.AsyncClient() as client:
    response = await client.post(
        "http://localhost:8000/api/v1/query",
        json={
            "dimensions": ["orders.status"],
            "measures": ["orders.count"]
        }
    )
    result = response.json()
    print(result["data"])
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test
python test_basic.py
python test_integration.py
python test_complete.py

# Test with Docker
docker-compose up -d
python test_real_api.py
```

## ğŸ—ï¸ Project Structure

```
semanticquark/
â”œâ”€â”€ semantic_layer/          # Core package
â”‚   â”œâ”€â”€ api/                # API layer (FastAPI)
â”‚   â”œâ”€â”€ config/             # Configuration
â”‚   â”œâ”€â”€ connectors/         # Database connectors
â”‚   â”œâ”€â”€ engine/              # Query engine
â”‚   â”œâ”€â”€ models/             # Data models
â”‚   â”œâ”€â”€ query/               # Query parsing
â”‚   â”œâ”€â”€ query_builder/      # SQL generation
â”‚   â””â”€â”€ result/             # Result formatting
â”œâ”€â”€ models/                  # Model definitions (YAML)
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ docker-compose.yml      # Docker setup
â”œâ”€â”€ Dockerfile              # Container definition
â””â”€â”€ requirements.txt        # Dependencies
```

## ğŸ”Œ Supported Data Sources

- âœ… PostgreSQL
- âœ… MySQL
- ğŸš§ Snowflake (coming soon)
- ğŸš§ BigQuery (coming soon)
- ğŸš§ Redshift (coming soon)

## ğŸ›£ï¸ Roadmap

### Phase 1: Core (âœ… Complete)
- [x] Semantic data modeling
- [x] REST API
- [x] PostgreSQL connector
- [x] Query parsing and SQL generation
- [x] Docker setup

### Phase 2: Enhanced Features (ğŸš§ In Progress)
- [ ] GraphQL API
- [ ] Caching layer (Redis)
- [ ] Pre-aggregations
- [ ] Row-level security
- [ ] More database connectors

### Phase 3: Advanced Features (ğŸ“‹ Planned)
- [ ] ML-powered metrics
- [ ] Natural language queries
- [ ] Query optimization
- [ ] Data lineage
- [ ] Visual model editor

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone and setup
git clone https://github.com/yourusername/semanticquark.git
cd semanticquark
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Run tests
pytest

# Format code
black semantic_layer/
ruff check semantic_layer/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by [Cube.js](https://github.com/cube-js/cube) - JavaScript semantic layer
- Built with [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- Uses [Pydantic](https://pydantic.dev/) - Data validation

## ğŸ“ Support

- ğŸ“– [Documentation](http://localhost:8000/docs)
- ğŸ› [Issue Tracker](https://github.com/yourusername/semanticquark/issues)
- ğŸ’¬ [Discussions](https://github.com/yourusername/semanticquark/discussions)

## â­ Star History

If you find this project useful, please consider giving it a star!

---

<div align="center">

**SemanticQuark - The Fundamental Building Block for Semantic Analytics**

Built with â¤ï¸ using Python

[Report Bug](https://github.com/yourusername/semanticquark/issues) â€¢ [Request Feature](https://github.com/yourusername/semanticquark/issues) â€¢ [Documentation](http://localhost:8000/docs)

</div>
