# SemanticQuark

<div align="center">

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Docker](https://img.shields.io/badge/docker-ready-blue.svg)

**The Fundamental Building Block for Semantic Analytics**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Examples](#-examples) â€¢ [Roadmap](#-roadmap) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸš€ What is SemanticQuark?

**SemanticQuark** is a Python-based semantic layer platform that provides the fundamental building blocks for analytics. It enables you to:

- **Define metrics once, use everywhere** - Create reusable data models with consistent metric definitions
- **Query data without SQL** - Use simple JSON queries instead of complex SQL
- **Connect to any database** - Support for PostgreSQL, MySQL, Snowflake, BigQuery, and more
- **Build faster analytics** - Intelligent caching and pre-aggregation for sub-second queries
- **Secure your data** - Row-level and column-level security built-in

Think of it as **Cube.js for Python** - but with native Python integration, ML capabilities, and data science workflow support. 

## âœ¨ Features

### Core Features
- ğŸ¯ **Semantic Data Modeling** - Define cubes, dimensions, and measures in YAML
- ğŸ” **REST API** - Query data with simple JSON requests
- ğŸ—„ï¸ **Multiple Data Sources** - PostgreSQL, MySQL, and extensible connector system
- âš¡ **Query Optimization** - Automatic SQL generation and optimization
- ğŸ“Š **Result Formatting** - Consistent JSON responses with metadata
- ğŸ”’ **Security Ready** - Foundation for row-level and column-level security

### Python-Native Advantages
- ğŸ **Python SDK** - Native Python client library
- ğŸ“ˆ **Data Science Integration** - Works with Pandas, Jupyter, and ML workflows
- ğŸ¤– **ML-Ready** - Embed ML models directly in metrics
- ğŸ“¦ **Rich Ecosystem** - Leverage Python's data science libraries

### Production Ready
- ğŸ³ **Docker Support** - Complete Docker Compose setup
- ğŸ“ **API Documentation** - Auto-generated Swagger/OpenAPI docs
- ğŸ§ª **Tested** - Comprehensive test suite
- ğŸ“š **Well Documented** - Extensive documentation and examples

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Client Applications                         â”‚
â”‚    (BI Tools, Dashboards, Custom Apps, APIs)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ REST/GraphQL APIs
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API Layer (FastAPI)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   REST   â”‚  â”‚ GraphQL  â”‚  â”‚   SQL    â”‚             â”‚
â”‚  â”‚   API    â”‚  â”‚   API    â”‚  â”‚   API    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Query Requests
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Query Engine & Orchestration                     â”‚
â”‚  Query Parser â†’ SQL Builder â†’ Executor                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Semantic   â”‚ â”‚   Cache    â”‚ â”‚  Security  â”‚
â”‚    Layer     â”‚ â”‚   Layer    â”‚ â”‚   Layer   â”‚
â”‚  (Models)    â”‚ â”‚  (Redis)   â”‚ â”‚  (RLS)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Source Connectors                â”‚
â”‚  PostgreSQL â”‚ MySQL â”‚ Snowflake â”‚ BigQuery   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Docker and Docker Compose (optional, for full stack)
- PostgreSQL (if not using Docker)

### Installation

#### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/semanticquark.git
cd semanticquark

# Start all services
docker-compose up -d

# Initialize database
docker-compose exec postgres psql -U semantic_user -d semantic_db < init_db.sql

# Test the API
curl http://localhost:8000/health
```

#### Option 2: Local Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/semanticquark.git
cd semanticquark

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your database connection

# Run the API
python -m semantic_layer.api.main
```

### Your First Query

1. **Create a model** in `models/orders.yaml`:
```yaml
cubes:
  - name: orders
    table: orders
    dimensions:
      status:
        type: string
        sql: status
      created_at:
        type: time
        sql: created_at
    measures:
      count:
        type: count
        sql: id
      total_revenue:
        type: sum
        sql: total_amount
```

2. **Query the API**:
```bash
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "dimensions": ["orders.status"],
    "measures": ["orders.count", "orders.total_revenue"]
  }'
```

3. **Get results**:
```json
{
  "data": [
    {
      "orders_status": "completed",
      "orders_count": 5,
      "orders_total_revenue": 925.0
    }
  ],
  "meta": {
    "execution_time_ms": 18.56,
    "row_count": 1
  }
}
```

## ğŸ“– Documentation

- [Architecture Guide](high_level_architecture.md) - High-level design and concepts
- [Foundational Components](core_foundational_components.md) - Core building blocks
- [API Documentation](http://localhost:8000/docs) - Interactive API docs (when running)
- [Docker Setup](DOCKER_SETUP.md) - Docker Compose guide
- [Postman Examples](POSTMAN_EXAMPLES.md) - API usage examples
- [Competitive Advantages](competitive_advantages.md) - Features vs Cube.js

## ğŸ“š Examples

### Example 1: Simple Aggregation
```json
{
  "measures": ["orders.count", "orders.total_revenue"]
}
```

### Example 2: Group By Dimension
```json
{
  "dimensions": ["orders.status"],
  "measures": ["orders.count"]
}
```

### Example 3: With Filters
```json
{
  "dimensions": ["orders.status"],
  "measures": ["orders.count"],
  "filters": [
    {
      "dimension": "orders.status",
      "operator": "equals",
      "values": ["completed"]
    }
  ]
}
```

### Example 4: Python Client
```python
import httpx

async with httpx.AsyncClient() as client:
    response = await client.post(
        "http://localhost:8000/api/v1/query",
        json={
            "dimensions": ["orders.status"],
            "measures": ["orders.count"]
        }
    )
    result = response.json()
    print(result["data"])
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test
python test_basic.py
python test_integration.py
python test_complete.py

# Test with Docker
docker-compose up -d
python test_real_api.py
```

## ğŸ—ï¸ Project Structure

```
semanticquark/
â”œâ”€â”€ semantic_layer/          # Core package
â”‚   â”œâ”€â”€ api/                # API layer (FastAPI)
â”‚   â”œâ”€â”€ config/             # Configuration
â”‚   â”œâ”€â”€ connectors/         # Database connectors
â”‚   â”œâ”€â”€ engine/              # Query engine
â”‚   â”œâ”€â”€ models/             # Data models
â”‚   â”œâ”€â”€ query/               # Query parsing
â”‚   â”œâ”€â”€ query_builder/      # SQL generation
â”‚   â””â”€â”€ result/             # Result formatting
â”œâ”€â”€ models/                  # Model definitions (YAML)
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ docker-compose.yml      # Docker setup
â”œâ”€â”€ Dockerfile              # Container definition
â””â”€â”€ requirements.txt        # Dependencies
```

## ğŸ”Œ Supported Data Sources

- âœ… PostgreSQL
- âœ… MySQL
- ğŸš§ Snowflake (coming soon)
- ğŸš§ BigQuery (coming soon)
- ğŸš§ Redshift (coming soon)

## ğŸ›£ï¸ Roadmap

### Phase 1: Core (âœ… Complete)
- [x] Semantic data modeling
- [x] REST API
- [x] PostgreSQL connector
- [x] Query parsing and SQL generation
- [x] Docker setup
- [x] Foundational query engine

### Phase 2: Enhanced Features (ğŸš§ In Progress)
- [ ] GraphQL API
- [ ] Caching layer (Redis)
- [ ] Pre-aggregations
- [ ] Row-level security (RLS)
- [ ] Snowflake connector
- [ ] BigQuery connector
- [ ] Query result caching
- [ ] Performance monitoring

### Phase 3: Monitoring & Observability (ğŸ“‹ Q1 2025)
- [ ] Extensible callback handler system
- [ ] Query logging and audit trail
- [ ] Performance metrics collection
- [ ] Integration with Elasticsearch
- [ ] Integration with LangSmith
- [ ] Slack alerts and notifications
- [ ] Custom handler framework
- [ ] Real-time query monitoring dashboard

### Phase 4: Advanced Security (ğŸ“‹ Q2 2025)
- [ ] Column-level security
- [ ] Data masking policies
- [ ] Audit logging
- [ ] API key management
- [ ] Role-based access control (RBAC)
- [ ] OAuth 2.0 integration
- [ ] SAML support
- [ ] Fine-grained permission system

### Phase 5: ML & Intelligence (ğŸ“‹ Q2-Q3 2025)
- [ ] ML-powered metric recommendations
- [ ] Anomaly detection
- [ ] Query optimization using ML
- [ ] Natural language to SQL (NL2SQL)
- [ ] Automatic dimension suggestion
- [ ] Cost estimation for queries
- [ ] Performance optimization recommendations
- [ ] Data lineage and impact analysis

### Phase 6: Enterprise Features (ğŸ“‹ Q3-Q4 2025)
- [ ] Data lineage tracking
- [ ] Multi-tenancy support
- [ ] Visual model editor (web UI)
- [ ] Model versioning and Git integration
- [ ] Data governance framework
- [ ] Compliance reporting (GDPR, HIPAA)
- [ ] Advanced scheduling and automation
- [ ] White-label deployment options

### Phase 7: Advanced Data Integration (ğŸ“‹ Q4 2025)
- [ ] Redshift connector
- [ ] Databricks connector
- [ ] Apache Spark integration
- [ ] Dremio integration
- [ ] Trino/Presto support
- [ ] Delta Lake support
- [ ] Apache Iceberg support
- [ ] Data lake connectors (S3, GCS, Azure)

### Phase 8: Performance & Scale (ğŸ“‹ 2026)
- [ ] Distributed query execution
- [ ] Query result streaming
- [ ] Connection pooling optimization
- [ ] Query execution plan visualization
- [ ] Advanced indexing strategies
- [ ] Materialized view automation
- [ ] Query parallelization
- [ ] Sub-second query performance (guaranteed)

### Phase 9: Community & Ecosystem (ğŸ“‹ 2026)
- [ ] Plugin marketplace
- [ ] Community handler library
- [ ] Third-party integrations (Tableau, Looker, PowerBI)
- [ ] SDK for JavaScript/TypeScript
- [ ] SDK for Go
- [ ] SDK for Java
- [ ] Community examples and templates
- [ ] Certification program

### Phase 10: Advanced Features (ğŸ“‹ 2026)
- [ ] Time-series analysis
- [ ] Cohort analysis
- [ ] Funnel analysis
- [ ] Retention analysis
- [ ] Attribution modeling
- [ ] A/B testing framework
- [ ] Experimentation platform
- [ ] Real-time metrics

---

## ğŸ“Š Roadmap Timeline

```
2024 Q4: Phase 1 (Core) âœ… + Phase 2 (Enhanced) ğŸš§
         â”‚
         â”œâ”€ Semantic modeling âœ…
         â”œâ”€ REST API âœ…
         â”œâ”€ PostgreSQL âœ…
         â”œâ”€ GraphQL API ğŸš§
         â””â”€ Caching layer ğŸš§
         
2025 Q1: Phase 3 (Monitoring) ğŸ“‹
         â”‚
         â”œâ”€ Callback handlers
         â”œâ”€ Query logging
         â”œâ”€ Performance metrics
         â””â”€ Elasticsearch integration
         
2025 Q2: Phase 4 (Security) + Phase 5 (ML) ğŸ“‹
         â”‚
         â”œâ”€ Column-level security
         â”œâ”€ ML recommendations
         â”œâ”€ NL2SQL
         â””â”€ Anomaly detection
         
2025 Q3: Phase 6 (Enterprise) ğŸ“‹
         â”‚
         â”œâ”€ Visual editor
         â”œâ”€ Data governance
         â”œâ”€ Git integration
         â””â”€ Multi-tenancy
         
2025 Q4: Phase 7 (Data Integration) ğŸ“‹
         â”‚
         â”œâ”€ Redshift
         â”œâ”€ Databricks
         â”œâ”€ Spark integration
         â””â”€ Delta Lake support
         
2026 H1: Phase 8 (Performance) ğŸ“‹
         â”‚
         â”œâ”€ Distributed execution
         â”œâ”€ Query streaming
         â”œâ”€ Optimization AI
         â””â”€ Sub-second queries
         
2026 H2: Phase 9-10 (Community & Advanced) ğŸ“‹
         â”‚
         â”œâ”€ Plugin marketplace
         â”œâ”€ Multi-SDK support
         â”œâ”€ Time-series analysis
         â””â”€ Experimentation platform
```

---

## ğŸ¯ Key Milestones

| Milestone | Target | Status |
|-----------|--------|--------|
| Core semantic layer | 2024 Q4 | âœ… Complete |
| Callback monitoring | 2025 Q1 | ğŸ“‹ Planned |
| Enterprise security | 2025 Q2 | ğŸ“‹ Planned |
| ML-powered features | 2025 Q2 | ğŸ“‹ Planned |
| Visual editor | 2025 Q3 | ğŸ“‹ Planned |
| 10+ connectors | 2025 Q4 | ğŸ“‹ Planned |
| Sub-second queries | 2026 Q1 | ğŸ“‹ Planned |
| Production scale | 2026 Q2 | ğŸ“‹ Planned |

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone and setup
git clone https://github.com/yourusername/semanticquark.git
cd semanticquark
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Run tests
pytest

# Format code
black semantic_layer/
ruff check semantic_layer/
```

### Areas Looking for Contributions
- ğŸ”Œ New database connectors (Snowflake, BigQuery, Redshift)
- ğŸ“Š Data source integrations
- ğŸ§ª Test coverage improvements
- ğŸ“š Documentation enhancements
- ğŸ› Bug fixes
- âœ¨ Feature implementations

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by [Cube.js](https://github.com/cube-js/cube) - JavaScript semantic layer
- Built with [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- Uses [Pydantic](https://pydantic.dev/) - Data validation

## ğŸ“ Support

- ğŸ“– [Documentation](http://localhost:8000/docs)
- ğŸ› [Issue Tracker](https://github.com/yourusername/semanticquark/issues)
- ğŸ’¬ [Discussions](https://github.com/yourusername/semanticquark/discussions)

## â­ Star History

If you find this project useful, please consider giving it a star!

---

<div align="center">

**SemanticQuark - The Fundamental Building Block for Semantic Analytics**

Built with â¤ï¸ using Python

[Report Bug](https://github.com/yourusername/semanticquark/issues) â€¢ [Request Feature](https://github.com/yourusername/semanticquark/issues) â€¢ [Documentation](http://localhost:8000/docs)

</div>